{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The audio-dataset-converter library (and its dependent libraries) can be used for converting audio datasets from one format into another. It has I/O support for the following domains: Audio classification Speech Please refer to the dataset formats section for more details on supported formats. But the library does not just convert datasets, you can also slot in complex filter pipelines to process/clean the data. On this website you can find examples and documentation for: Audio classification Speech Filter usage Placeholders Execution control External functions Multiple I/O Email File handling Temporary storage Docker usage Examples for the additional libraries: Faster whisper Redis Visualization","title":"Home"},{"location":"audio_classification/","text":"Readers and writers for audio classification have the -ac suffix. Plugins # sub-dir to ADAMS # The following converts an audio classification dataset from the sub-dir format (sub-directory names represent the audio classification labels) into the ADAMS format , which stores the label in an associated .report file (Java properties file): adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i ./subdir/ \\ to-adams-ac \\ -l INFO \\ -o ./adams \\ -c classification sub-dir (randomized train/val/test splits) # By enforcing batch-processing --force_batch and using the randomize-records filter, randomized train/val/test splits (writers typically support generating splits) can be generated like this: adc-convert -l INFO --force_batch \\ from-subdir-ac \\ -l INFO \\ -i ./subdir/ \\ randomize-records \\ -s 42 \\ to-subdir-ac \\ -l INFO \\ -o ./subdir-split \\ -c classification \\ --split_names train val test \\ --split_ratios 70 15 15","title":"Audio classification"},{"location":"audio_classification/#plugins","text":"","title":"Plugins"},{"location":"audio_classification/#sub-dir-to-adams","text":"The following converts an audio classification dataset from the sub-dir format (sub-directory names represent the audio classification labels) into the ADAMS format , which stores the label in an associated .report file (Java properties file): adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i ./subdir/ \\ to-adams-ac \\ -l INFO \\ -o ./adams \\ -c classification","title":"sub-dir to ADAMS"},{"location":"audio_classification/#sub-dir-randomized-trainvaltest-splits","text":"By enforcing batch-processing --force_batch and using the randomize-records filter, randomized train/val/test splits (writers typically support generating splits) can be generated like this: adc-convert -l INFO --force_batch \\ from-subdir-ac \\ -l INFO \\ -i ./subdir/ \\ randomize-records \\ -s 42 \\ to-subdir-ac \\ -l INFO \\ -o ./subdir-split \\ -c classification \\ --split_names train val test \\ --split_ratios 70 15 15","title":"sub-dir (randomized train/val/test splits)"},{"location":"docker/","text":"Below are examples for using the audio-dataset-converter library via its Docker images . Interactive session # The following command starts an interactive session, mapping the current working directory to /workspace : docker run --rm -u $(id -u):$(id -g) \\ -v `pwd`:/workspace \\ -it waikatodatamining/audio-dataset-converter:latest Conversion pipeline # The following converts an audio classification dataset from the sub-dir format (sub-directory names represent the audio classification labels) into the ADAMS format , which stores the label in an associated .report file (Java properties file): docker run --rm -u $(id -u):$(id -g) \\ -v `pwd`:/workspace \\ -it waikatodatamining/audio-dataset-converter:latest \\ adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i /workspace/input/ \\ to-adams-ac \\ -l INFO \\ -o /workspace/output \\ -c classification NB: The input and output directories are located below the current working directory ( pwd ).","title":"Docker usage"},{"location":"docker/#interactive-session","text":"The following command starts an interactive session, mapping the current working directory to /workspace : docker run --rm -u $(id -u):$(id -g) \\ -v `pwd`:/workspace \\ -it waikatodatamining/audio-dataset-converter:latest","title":"Interactive session"},{"location":"docker/#conversion-pipeline","text":"The following converts an audio classification dataset from the sub-dir format (sub-directory names represent the audio classification labels) into the ADAMS format , which stores the label in an associated .report file (Java properties file): docker run --rm -u $(id -u):$(id -g) \\ -v `pwd`:/workspace \\ -it waikatodatamining/audio-dataset-converter:latest \\ adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i /workspace/input/ \\ to-adams-ac \\ -l INFO \\ -o /workspace/output \\ -c classification NB: The input and output directories are located below the current working directory ( pwd ).","title":"Conversion pipeline"},{"location":"email/","text":"Whilst most readers and writers are file-based, it is also possible to retrieve and send emails using the following: get-email - retrieve emails from an IMAP folder, FROM and SUBJECT can be stored in placeholders send-email - send emails via SMTP, the from/to/subject/body options automatically expand placeholders The connection parameters are obtained through environment variables that are stored in .env files. The following pipeline uses the get-email reader to poll the audio folder for new messages with WAV attachments every 5 seconds. These audio files get downloaded and then forwarded to the send-email writer that attaches the audio files and then sends an email to the specified email address: adc-convert -l INFO \\ get-email \\ -l INFO \\ -f audio \\ -o {TMP} \\ -r \".*\\.(wav|WAV)\" \\ -w 5 \\ --only_unseen \\ --mark_as_read \\ --from_placeholder FROM \\ --subject_placeholder SUBJECT \\ send-email \\ -l INFO \\ -f from@example.com \\ -t someone@anotherexample.com \\ -s {SUBJECT} \\ -b \"Message from: {FROM}\"","title":"Email"},{"location":"execution_control/","text":"The following filters can be used for controlling the execution of the pipeline: block - blocks data passing through based on a condition applied to the meta-data list-to-sequence - forwards the elements of lists individually stop - stops the pipeline if the meta-data-based condition holds true sub-process - meta-data condition determines execution of sub-filter(s) tee - meta-data condition determines forking off of data to the sub-pipeline (filter(s), [writer]) trigger - meta-data condition determines execution of the sub-pipeline (reader, [filter(s)], [writer]) Sub-pipelines # With the tee meta-filter, it is possible to filter the audio files coming through with a separate sub-pipeline. E.g., converting the incoming data into multiple output formats with their own preprocessing. The following command loads the Festvox speech data and saves them in ADAMS and split ADAMS format (after trimming silences) in one command: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ tee \\ -f \"to-adams-sp -o ./adams-tee/ -t transcript\" \\ tee \\ -f \"trim-silence to-adams-sp -o ./adams-split-tee/ -t transcript --split_names train val test --split_ratios 70 15 15\"","title":"Execution control"},{"location":"execution_control/#sub-pipelines","text":"With the tee meta-filter, it is possible to filter the audio files coming through with a separate sub-pipeline. E.g., converting the incoming data into multiple output formats with their own preprocessing. The following command loads the Festvox speech data and saves them in ADAMS and split ADAMS format (after trimming silences) in one command: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ tee \\ -f \"to-adams-sp -o ./adams-tee/ -t transcript\" \\ tee \\ -f \"trim-silence to-adams-sp -o ./adams-split-tee/ -t transcript --split_names train val test --split_ratios 70 15 15\"","title":"Sub-pipelines"},{"location":"faster_whisper/","text":"Requirements # Requires the audio-dataset-converter-faster-whisper library. Plugins # Transcribing audio # The following commands loads raw audio files (i.e., ones without a transcript) and applies the fw-transcribe filter to generate a transcript using faster-whisper, with the result then being stored in Festvox format: adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./raw/*.wav\" \\ -t sp \\ fw-transcribe \\ -l INFO \\ to-festvox-sp \\ -l INFO \\ -o ./festvox Tools # Generate SRT subtitles # The adc-srt allows generating subtitles in SRT format from audio and video files. The following example generates subtitle files for all .mp4 file, alongside the video files: adc-srt \\ -l INFO \\ -i ./input/*.mp4 In this example, the .srt files generated from .wav files get placed in a separate output directory: adc-srt \\ -l INFO \\ -i ./input/*.wav \\ -o ./output","title":"Faster whisper"},{"location":"faster_whisper/#requirements","text":"Requires the audio-dataset-converter-faster-whisper library.","title":"Requirements"},{"location":"faster_whisper/#plugins","text":"","title":"Plugins"},{"location":"faster_whisper/#transcribing-audio","text":"The following commands loads raw audio files (i.e., ones without a transcript) and applies the fw-transcribe filter to generate a transcript using faster-whisper, with the result then being stored in Festvox format: adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./raw/*.wav\" \\ -t sp \\ fw-transcribe \\ -l INFO \\ to-festvox-sp \\ -l INFO \\ -o ./festvox","title":"Transcribing audio"},{"location":"faster_whisper/#tools","text":"","title":"Tools"},{"location":"faster_whisper/#generate-srt-subtitles","text":"The adc-srt allows generating subtitles in SRT format from audio and video files. The following example generates subtitle files for all .mp4 file, alongside the video files: adc-srt \\ -l INFO \\ -i ./input/*.mp4 In this example, the .srt files generated from .wav files get placed in a separate output directory: adc-srt \\ -l INFO \\ -i ./input/*.wav \\ -o ./output","title":"Generate SRT subtitles"},{"location":"file_handling/","text":"Reading/writing text files # from-text-file - this reader reads the file line by line and forwards them to-text-file - writes the incoming strings to the specified text file Listing files # list-files - simply lists files in a directory forwards the list poll-dir - polls a directory for files to process, can move or delete them after they were processed by the specified base-reader watch-dir - uses a file-system watchdog to look for changes to files (events: created or modified) and forwards these to the base-reader, can move or delete these files after processing as well Others # copy-files - copies the incoming files into the specified target directory delete-files - deletes the incoming files move-files - moves the incoming files into the specified target directory","title":"File handling"},{"location":"file_handling/#readingwriting-text-files","text":"from-text-file - this reader reads the file line by line and forwards them to-text-file - writes the incoming strings to the specified text file","title":"Reading/writing text files"},{"location":"file_handling/#listing-files","text":"list-files - simply lists files in a directory forwards the list poll-dir - polls a directory for files to process, can move or delete them after they were processed by the specified base-reader watch-dir - uses a file-system watchdog to look for changes to files (events: created or modified) and forwards these to the base-reader, can move or delete these files after processing as well","title":"Listing files"},{"location":"file_handling/#others","text":"copy-files - copies the incoming files into the specified target directory delete-files - deletes the incoming files move-files - moves the incoming files into the specified target directory","title":"Others"},{"location":"filters/","text":"The following sections only show snippets of commands, as there are quite a number of filters available. Annotation management # strip-annotations - removes all annotations Audio management # convert-to-mono - ensures that audio data is mono convert-to-wav - ensures that audio data is in WAV format trim-silence - for removing chunks of silence Trimming the silence: adc-convert -l INFO \\ from-data \\ -l INFO \\ -t sp \\ -i \"./input/*.wav\" \\ trim-silence \\ -l INFO \\ to-data \\ -l INFO \\ -o ./output Augmentation # pitch-shift - for shifting the pitch of audio samples time-stretch - for speeding up/slowing down samples Meta-data management # metadata - allows comparisons on meta-data values and whether to keep or discard a record in case of a match metadata-from-name - allows extraction of meta-data value from the audio file name via a regular expression metadata-to-placeholder - sets the specified placeholder using the data from the meta-data passing through set-metadata - sets the meta-data key/value pair as data passes through, can make use of data passing through as well split-records - adds a field to the meta-data (default: split ) of the record passing through, which can be acted on with other filters (or stored in the output) Splitting records into train/test using a 50/50 split ratio: sdc-convert -l INFO -b \\ from-data \\ -l INFO \\ -t sp \\ -i \"./input/*.wav\" \\ split-records \\ --split_names train test \\ --split_ratios 50 50 \\ set-placeholder to-data \\ -l INFO \\ -o ./output Record management # A number of generic record management filters are available: check-duplicate-filenames - when using multiple batches as input, duplicate file names can be an issue when creating a combined output discard-by-name - discards files based on their name, either using explicit names or regular expressions discard-negatives - removes records from the stream that have no annotations max-records - limits the number of records passing through randomize-records - when processing batches, this filter can randomize them (seeded or unseeded) record-window - only lets a certain window of records pass through (e.g., the first 1000) rename - allows renaming of audio files, e.g., prefixing them with a batch number/ID sample - for selecting a random sub-sample from the stream Discarding files by name: adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i ./input/ \\ discard-by-name \\ -l INFO \\ -r \"jvm_00027.*\" \\ to-subdir-ac \\ -l INFO \\ -o ./output","title":"Filter usage"},{"location":"filters/#annotation-management","text":"strip-annotations - removes all annotations","title":"Annotation management"},{"location":"filters/#audio-management","text":"convert-to-mono - ensures that audio data is mono convert-to-wav - ensures that audio data is in WAV format trim-silence - for removing chunks of silence Trimming the silence: adc-convert -l INFO \\ from-data \\ -l INFO \\ -t sp \\ -i \"./input/*.wav\" \\ trim-silence \\ -l INFO \\ to-data \\ -l INFO \\ -o ./output","title":"Audio management"},{"location":"filters/#augmentation","text":"pitch-shift - for shifting the pitch of audio samples time-stretch - for speeding up/slowing down samples","title":"Augmentation"},{"location":"filters/#meta-data-management","text":"metadata - allows comparisons on meta-data values and whether to keep or discard a record in case of a match metadata-from-name - allows extraction of meta-data value from the audio file name via a regular expression metadata-to-placeholder - sets the specified placeholder using the data from the meta-data passing through set-metadata - sets the meta-data key/value pair as data passes through, can make use of data passing through as well split-records - adds a field to the meta-data (default: split ) of the record passing through, which can be acted on with other filters (or stored in the output) Splitting records into train/test using a 50/50 split ratio: sdc-convert -l INFO -b \\ from-data \\ -l INFO \\ -t sp \\ -i \"./input/*.wav\" \\ split-records \\ --split_names train test \\ --split_ratios 50 50 \\ set-placeholder to-data \\ -l INFO \\ -o ./output","title":"Meta-data management"},{"location":"filters/#record-management","text":"A number of generic record management filters are available: check-duplicate-filenames - when using multiple batches as input, duplicate file names can be an issue when creating a combined output discard-by-name - discards files based on their name, either using explicit names or regular expressions discard-negatives - removes records from the stream that have no annotations max-records - limits the number of records passing through randomize-records - when processing batches, this filter can randomize them (seeded or unseeded) record-window - only lets a certain window of records pass through (e.g., the first 1000) rename - allows renaming of audio files, e.g., prefixing them with a batch number/ID sample - for selecting a random sub-sample from the stream Discarding files by name: adc-convert -l INFO \\ from-subdir-ac \\ -l INFO \\ -i ./input/ \\ discard-by-name \\ -l INFO \\ -r \"jvm_00027.*\" \\ to-subdir-ac \\ -l INFO \\ -o ./output","title":"Record management"},{"location":"multi/","text":"Most of the time, conversion pipelines will only need to read from one source and output to a single target. However, there can be cases where datasets of different types need merging ( multiple inputs ) or datasets of different types need to generated for different frameworks ( multiple outputs ). To cater for these scenarios, the following two meta plugins are available: from-multi - reads from one or more sources using the specified readers to-multi - forwards the incoming data to one or more writers There is one restriction, each of the base reader/writer must be from the same data domain. Multiple inputs # The following command reads a dataset in Festvox and ADAMS format, with the combined output being saved in CommonVoice format: adc-convert \\ -l INFO \\ from-multi \\ -l INFO \\ -t sp \\ -r \"from-festvox-sp -l INFO -i {CWD}/input/*.txt\" \\ \"from-adams-sp -l INFO -i {CWD}/input/*.report -t transcript\" \\ to-commonvoice-sp \\ -l INFO \\ -o \"{CWD}/output\" Multiple outputs # Below, the source data is in ADAMS speech format and will be converted to Festvox and CommonVoice format: adc-convert \\ -l INFO \\ from-adams-sp \\ -l INFO \\ -i \"{CWD}/input/*.report\" \\ to-multi \\ -l INFO \\ -t sp \\ -w \"to-festvox-sp -l INFO -o {CWD}/output/festvox\" \\ \"to-commonvoice-sp -l INFO -o {CWD}/output/commonvoice\"","title":"Multiple I/O"},{"location":"multi/#multiple-inputs","text":"The following command reads a dataset in Festvox and ADAMS format, with the combined output being saved in CommonVoice format: adc-convert \\ -l INFO \\ from-multi \\ -l INFO \\ -t sp \\ -r \"from-festvox-sp -l INFO -i {CWD}/input/*.txt\" \\ \"from-adams-sp -l INFO -i {CWD}/input/*.report -t transcript\" \\ to-commonvoice-sp \\ -l INFO \\ -o \"{CWD}/output\"","title":"Multiple inputs"},{"location":"multi/#multiple-outputs","text":"Below, the source data is in ADAMS speech format and will be converted to Festvox and CommonVoice format: adc-convert \\ -l INFO \\ from-adams-sp \\ -l INFO \\ -i \"{CWD}/input/*.report\" \\ to-multi \\ -l INFO \\ -t sp \\ -w \"to-festvox-sp -l INFO -o {CWD}/output/festvox\" \\ \"to-commonvoice-sp -l INFO -o {CWD}/output/commonvoice\"","title":"Multiple outputs"},{"location":"placeholders/","text":"Juggling longs paths in command-lines can be nightmare, which is the reason the spectral-data-converter library offers support for placeholders . Placeholders can be used to shorten paths and making command-lines easier to transfer to another environment or user. Placeholders (format {PH} ) get expanded dynamically at runtime, taking the current state into account. Placeholder types # There are different types of placeholders: System-defined ones: {HOME} - the user's home directory {CWD} - the current working directory {TMP} - the temporary directory Input-based ones, which are based on the current input file being processed: {INPUT_PATH} - the directory component of the current file {INPUT_NAMEEXT} - the name (incl ext) of the current file {INPUT_NAMENOEXT} - the name (excl ext) of the current file {INPUT_EXT} - the extension of the current file {INPUT_PARENT_PATH} - the path of the file's parent {INPUT_PARENT_NAME} - the name of the file's parent User-defined ones, which are supplied to the tool itself, e.g., via the -p/--placeholders option of the adc-convert tool. The same script can be executed using different directories when using different placeholder setups. The format for the placeholders files is simple, one placeholder per line using placeholder=value as format. Empty lines and ones starting with # get ignored. Runtime ones, which can be set with the set-placeholder plugin. These placeholders can be based on other placeholders. The reason for this plugin is that the output of some filters may not have any directory associated with them anymore, only a file name. That renders all the input-based placeholders unusable. Using set-placeholder beforehand allows saving the input directory in another placeholder for later use. Meta-data can be used as placeholders as well using the metadata-to-placeholder plugin, which extracts a particular key from the metadata passing through and updates the specified placeholder accordingly. Examples # Relative to input # The following command places the converted data on the same level as the input directory data1 in a directory called data2 : adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -t sp \\ -i \"/some/where/data1/*.wav\" \\ to-data \\ -l INFO \\ -o {INPUT_PARENT_PATH}/data2 In-place predictions # When trying to convert audio files into another format and place them in the same location as the input ones, manually copying files is rather tedious. Also, filters that get rid of the file path and only forward the file name, like convert-to-wav , invalidate the use of input-based placeholders like {INPUT_PATH} . For that reason, the set-placeholder plugin can be used to back up such placeholders in other user-defined placeholders. The following pipeline backs up {INPUT_PATH} in the new placeholder {OUTPUT_DIR} and uses that for saving the original .mp3 files as .wav ones: adc-convert -l INFO \\ from-data \\ -t sp \\ -i \"/some/where/*.mp3\" \\ set-placeholder \\ -l INFO \\ -p OUTPUT_DIR \\ -v \"{INPUT_PATH}\" \\ convert-to-wav \\ to-data \\ -l INFO \\ -o \"{OUTPUT_DIR}\"","title":"Placeholders"},{"location":"placeholders/#placeholder-types","text":"There are different types of placeholders: System-defined ones: {HOME} - the user's home directory {CWD} - the current working directory {TMP} - the temporary directory Input-based ones, which are based on the current input file being processed: {INPUT_PATH} - the directory component of the current file {INPUT_NAMEEXT} - the name (incl ext) of the current file {INPUT_NAMENOEXT} - the name (excl ext) of the current file {INPUT_EXT} - the extension of the current file {INPUT_PARENT_PATH} - the path of the file's parent {INPUT_PARENT_NAME} - the name of the file's parent User-defined ones, which are supplied to the tool itself, e.g., via the -p/--placeholders option of the adc-convert tool. The same script can be executed using different directories when using different placeholder setups. The format for the placeholders files is simple, one placeholder per line using placeholder=value as format. Empty lines and ones starting with # get ignored. Runtime ones, which can be set with the set-placeholder plugin. These placeholders can be based on other placeholders. The reason for this plugin is that the output of some filters may not have any directory associated with them anymore, only a file name. That renders all the input-based placeholders unusable. Using set-placeholder beforehand allows saving the input directory in another placeholder for later use. Meta-data can be used as placeholders as well using the metadata-to-placeholder plugin, which extracts a particular key from the metadata passing through and updates the specified placeholder accordingly.","title":"Placeholder types"},{"location":"placeholders/#examples","text":"","title":"Examples"},{"location":"placeholders/#relative-to-input","text":"The following command places the converted data on the same level as the input directory data1 in a directory called data2 : adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -t sp \\ -i \"/some/where/data1/*.wav\" \\ to-data \\ -l INFO \\ -o {INPUT_PARENT_PATH}/data2","title":"Relative to input"},{"location":"placeholders/#in-place-predictions","text":"When trying to convert audio files into another format and place them in the same location as the input ones, manually copying files is rather tedious. Also, filters that get rid of the file path and only forward the file name, like convert-to-wav , invalidate the use of input-based placeholders like {INPUT_PATH} . For that reason, the set-placeholder plugin can be used to back up such placeholders in other user-defined placeholders. The following pipeline backs up {INPUT_PATH} in the new placeholder {OUTPUT_DIR} and uses that for saving the original .mp3 files as .wav ones: adc-convert -l INFO \\ from-data \\ -t sp \\ -i \"/some/where/*.mp3\" \\ set-placeholder \\ -l INFO \\ -p OUTPUT_DIR \\ -v \"{INPUT_PATH}\" \\ convert-to-wav \\ to-data \\ -l INFO \\ -o \"{OUTPUT_DIR}\"","title":"In-place predictions"},{"location":"pyfunc/","text":"No library can dream of offering all the required functionality. Especially for one-off tasks, it makes no sense to develop a whole new plugin library. Hence, there are the following generic plugins that allow the user to utilize custom Python functions: reader: from-pyfunc - takes a single string as input and outputs an iterable of audio containers (as per specified data type) filter: pyfunc-filter - takes a single audio container or an iterable of them as input and outputs a single container or an iterable of them (as per specified input and output data types) writer: to-pyfunc - processes a single audio container or an iterable of them as per specified data type and an optional split name In order to use such a custom function, they must be specified in the following format (option: -f/--function ): module_name:function_name If the code below were available through module my.code , then the function specifications would be as follows: reader: my.code:pyfunc_reader filter: my.code:pyfunc_filter writer: my.code:pyfunc_writer from typing import Iterable from adc.api import AudioClassificationData, make_list, flatten_list # reader: generates audio classification containers from the path def pyfunc_reader(path: str) -> Iterable[AudioClassificationData]: return [AudioClassificationData(source=path)] # filter: simply adds a note to the meta-data def pyfunc_filter(data): result = [] for item in make_list(data): if not item.has_metadata(): meta = dict() else: meta = item.get_metadata() meta[\"note\"] = \"filtered by a python function!\" item.set_metadata(meta) result.append(item) return flatten_list(result) # writer: simply outputs name and meta-data and, if present, also the split def pyfunc_writer(data: AudioClassificationData, split: str = None): if split is None: print(\"name: \", data.audio_name, \", meta:\", data.get_metadata()) else: print(\"split:\", split, \", name:\", data.audio_name, \", meta:\", data.get_metadata())","title":"External functions"},{"location":"redis/","text":"Requirements # Requires the audio-dataset-converter-redis library. Plugins # Transcribing audio # The following commands loads raw audio files (i.e., ones without a transcript) and applies the redis-transcribe filter to generate a transcript using faster-whisper, with the result then being stored in Festvox format: First, start the faster-whisper process via Docker (using the CPU): docker run --rm \\ -u $(id -u):$(id -g) -e USER=$USER \\ --shm-size 8G \\ --net=host \\ -v `pwd`:/workspace \\ -v `pwd`/cache:/.cache \\ -it public.aml-repo.cms.waikato.ac.nz:443/pytorch/python-faster-whisper:1.0.2_cpu \\ fw_predict_redis \\ --redis_in audio \\ --redis_out transcript \\ --model_size base \\ --verbose And now apply the pipeline to have the audio files transcribed: adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./raw/*.wav\" \\ -t sp \\ redis-transcribe \\ -l INFO \\ --channel_out audio \\ --channel_in transcript \\ to-festvox-sp \\ -l INFO \\ -o ./festvox","title":"Redis"},{"location":"redis/#requirements","text":"Requires the audio-dataset-converter-redis library.","title":"Requirements"},{"location":"redis/#plugins","text":"","title":"Plugins"},{"location":"redis/#transcribing-audio","text":"The following commands loads raw audio files (i.e., ones without a transcript) and applies the redis-transcribe filter to generate a transcript using faster-whisper, with the result then being stored in Festvox format: First, start the faster-whisper process via Docker (using the CPU): docker run --rm \\ -u $(id -u):$(id -g) -e USER=$USER \\ --shm-size 8G \\ --net=host \\ -v `pwd`:/workspace \\ -v `pwd`/cache:/.cache \\ -it public.aml-repo.cms.waikato.ac.nz:443/pytorch/python-faster-whisper:1.0.2_cpu \\ fw_predict_redis \\ --redis_in audio \\ --redis_out transcript \\ --model_size base \\ --verbose And now apply the pipeline to have the audio files transcribed: adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./raw/*.wav\" \\ -t sp \\ redis-transcribe \\ -l INFO \\ --channel_out audio \\ --channel_in transcript \\ to-festvox-sp \\ -l INFO \\ -o ./festvox","title":"Transcribing audio"},{"location":"speech/","text":"Readers and writers for speech have the -sp suffix. Download the Iris Living Audio Dataset dataset in Festvox format and extract it. Plugins # Festvox to ADAMS # The following converts the Festvoc dataset into ADAMS format, storing the transcript in the transcript field: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ to-adams-sp \\ -l INFO \\ -o ./adams \\ -t transcript Festvox to ADAMS (train/val/test splits) # You can also split the data, e.g., into train, validation and test subsets. The following converts the Festvox into ADAMS format: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ to-adams-sp \\ -l INFO \\ -o ./adams-split \\ -t transcript \\ --split_names train val test \\ --split_ratios 70 15 15 NB: The subsets will be placed into sub-directories according to the split name.","title":"Speech"},{"location":"speech/#plugins","text":"","title":"Plugins"},{"location":"speech/#festvox-to-adams","text":"The following converts the Festvoc dataset into ADAMS format, storing the transcript in the transcript field: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ to-adams-sp \\ -l INFO \\ -o ./adams \\ -t transcript","title":"Festvox to ADAMS"},{"location":"speech/#festvox-to-adams-trainvaltest-splits","text":"You can also split the data, e.g., into train, validation and test subsets. The following converts the Festvox into ADAMS format: adc-convert \\ -l INFO \\ from-festvox-sp \\ -l INFO \\ -i \"./festvox/*.txt\" \\ to-adams-sp \\ -l INFO \\ -o ./adams-split \\ -t transcript \\ --split_names train val test \\ --split_ratios 70 15 15 NB: The subsets will be placed into sub-directories according to the split name.","title":"Festvox to ADAMS (train/val/test splits)"},{"location":"storage/","text":"The following pipeline components can be used for storing and retrieving data from temporary storage (i.e., a dictionary) that is available through the session object of the pipeline: delete-storage - filter that removes the name storage item from-storage - reader retrieves the named storage item set-storage - filter that updates the storage with the data passing through to-storage - writer that updates the storage with the data arriving For annotations, you can use these specialized filters: annotations-from-storage - replaces the annotations of the current container with the ones from storage annotations-to-storage - pushes the annotations of the current container into internal storage","title":"Temporary storage"},{"location":"visualization/","text":"Requirements # Requires the audio-dataset-converter-visualization library. Plugins # For the following examples, data from the LJ Speech Dataset was used. Mel spectrogram # to-mel-spectrogram - outputs Mel spectrogram images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-mel-spectrogram \\ -l INFO \\ -o ./output MFCC spectrogram # to-mfcc-spectrogram - outputs Mel-frequency cepstral coefficients images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-mfcc-spectrogram \\ -l INFO \\ -o ./output STFT spectrogram # to-stft-spectrogram - outputs short time fourier transform (STFT) spectrogram images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-stft-spectrogram \\ -l INFO \\ -o ./output","title":"Visualization"},{"location":"visualization/#requirements","text":"Requires the audio-dataset-converter-visualization library.","title":"Requirements"},{"location":"visualization/#plugins","text":"For the following examples, data from the LJ Speech Dataset was used.","title":"Plugins"},{"location":"visualization/#mel-spectrogram","text":"to-mel-spectrogram - outputs Mel spectrogram images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-mel-spectrogram \\ -l INFO \\ -o ./output","title":"Mel spectrogram"},{"location":"visualization/#mfcc-spectrogram","text":"to-mfcc-spectrogram - outputs Mel-frequency cepstral coefficients images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-mfcc-spectrogram \\ -l INFO \\ -o ./output","title":"MFCC spectrogram"},{"location":"visualization/#stft-spectrogram","text":"to-stft-spectrogram - outputs short time fourier transform (STFT) spectrogram images adc-convert \\ -l INFO \\ from-data \\ -l INFO \\ -i \"./input/*.wav\" \\ -t sp \\ to-stft-spectrogram \\ -l INFO \\ -o ./output","title":"STFT spectrogram"}]}